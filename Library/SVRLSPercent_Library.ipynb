{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T16:21:27.624522Z",
     "start_time": "2021-06-30T16:21:27.600477Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVR_PerLs:\n",
    "    \"\"\"\n",
    "    SVR-LS based on Percentage error \n",
    "    Fits models where the values of the target variable are positive.\n",
    "    \n",
    "        -- Parameter --\n",
    "            C: Parameter that determines the weight of the penalization term in the model \n",
    "               (Default = 0.1)\n",
    "                        \n",
    "            kernel: name of the kernel that the model will use. Written in a string format.\n",
    "                    (Default = \"linear\"). \n",
    "        \n",
    "                    acceptable parameters: \n",
    "                        \"linear\", \"poly\", \"polynomial\", \"rbf\", \n",
    "                        \"laplacian\", \"cosine\".\n",
    "        \n",
    "                    for more information about individual kernels, visit the \n",
    "                    sklearn pairwise metrics affinities and kernels user guide.\n",
    "                    \n",
    "                    https://scikit-learn.org/stable/modules/metrics.html\n",
    "            \n",
    "            Specific kernel parameters: \n",
    "\n",
    "        --Methods--\n",
    "            fit(X, y): Learn from the data. Returns self.\n",
    "\n",
    "            predict(X_test): Predicts new points. Returns X_test labels.\n",
    "\n",
    "            coef_(): Returns w and b for linear models. Otherwise, returns alpha\n",
    "                (dual vector), b (intercept) and X from the dataset.\n",
    "\n",
    "            For more information about each method, visit specific documentations.\n",
    "            \n",
    "        --Example-- \n",
    "            ## Load the library in a jupyter notebook\n",
    "            >>> %run SVRLSPercent_Library\n",
    "            ...\n",
    "            ## Initialize the SVR object with custom parameters\n",
    "            >>> model = SVR_PerLs(C = 10, kernel = \"rbf\", gamma = 0.1)\n",
    "            ...\n",
    "            ## Use the model to fit the data\n",
    "            >>> fitted_model = model.fit(X, y)\n",
    "            ...\n",
    "            ## Predict with the given model\n",
    "            >>> y_prediction = fitted_model.predict(X_test)\n",
    "            ...\n",
    "            ## e.g\n",
    "            >>> print(y_prediction)\n",
    "            np.array([12.8, 31.6, 16.2, 90.5, 28, 1, 49.7])\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, C = 0.1, kernel = \"linear\", **kernel_param):\n",
    "        import numpy as np\n",
    "        from numpy.linalg import inv\n",
    "        from sklearn.metrics.pairwise import pairwise_kernels\n",
    "        from sklearn.utils import check_X_y, check_array\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.pairwise_kernels = pairwise_kernels\n",
    "        self.kernel_param = kernel_param\n",
    "        self.check_X_y = check_X_y\n",
    "        self.check_array = check_array\n",
    "        self.inv = inv\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\" \n",
    "        Computes coefficients for new data prediction.\n",
    "        \n",
    "            --Parameters--\n",
    "                X: nxm matrix that contains all data points\n",
    "                   components. n is the number of points and\n",
    "                   m is the number of features of each point.\n",
    "                   \n",
    "                y: nx1 matrix that contains labels for all\n",
    "                   the points.\n",
    "            \n",
    "            --Returns--\n",
    "                self, containing all the parameters needed to \n",
    "                compute new data points.\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = self.check_X_y(X, y)\n",
    "        # hyperparameters\n",
    "        C = self.C \n",
    "        \n",
    "        kernel = self.kernel\n",
    "        pairwise_kernels = self.pairwise_kernels\n",
    "        inv = self.inv\n",
    "        \n",
    "        # omega + upsilon\n",
    "        omega_ = pairwise_kernels(X, X, kernel, **self.kernel_param) + np.identity(y.size)*((y**2)/C)\n",
    "        # ones vector\n",
    "        onev = np.ones(y.shape).reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        # solve for parameters\n",
    "        A = np.linalg.pinv(np.block([[0, onev.T],[onev, omega_]]))\n",
    "        B = np.concatenate((np.array([0]),y.reshape(-1)))\n",
    "        sol =  A @ B\n",
    "        \n",
    "        b = sol[0]\n",
    "        alpha = sol[1:]\n",
    "        \n",
    "        self.X = X\n",
    "        self.alpha = alpha; self.b = b\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_):\n",
    "        \n",
    "        \"\"\" \n",
    "        Computes coefficients for new data prediction.\n",
    "        \n",
    "            --Parameters--\n",
    "                X: nxm matrix that contains all data points\n",
    "                   components. n is the number of points and\n",
    "                   m is the number of features of each point.\n",
    "                   \n",
    "                y: nx1 matrix that contains labels for all\n",
    "                   the points.\n",
    "            \n",
    "            --Returns--\n",
    "                self, containing all the parameters needed to \n",
    "                compute new data points.\n",
    "        \"\"\"\n",
    "        \n",
    "        pairwise_kernels = self.pairwise_kernels\n",
    "        kernel_param = self.kernel_param\n",
    "        kernel = self.kernel\n",
    "        alpha = self.alpha\n",
    "        b = self.b\n",
    "        X = self.X\n",
    "        \n",
    "        X_ = self.check_array(X_)\n",
    "        predict = alpha @ pairwise_kernels(X, X_, metric = kernel, **kernel_param) + b\n",
    "        return predict\n",
    "    \n",
    "    \n",
    "        # coefficient\n",
    "        \"\"\"--Returns--\n",
    "                Linear:\n",
    "                - weights\n",
    "                - intercept\n",
    "                \n",
    "                Non-Linear:\n",
    "                - dual coefficient\n",
    "                - support vector\n",
    "                - intercept\n",
    "        \"\"\"\n",
    "    def coef_(self):\n",
    "        if self.kernel == \"linear\":\n",
    "            alpha = self.alpha; X = self.X\n",
    "            w = alpha @ X\n",
    "            return w, self.b\n",
    "        else: \n",
    "            return self.alpha,  self.b, self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
